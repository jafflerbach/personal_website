---
title: "Santa Barbara's nature-based 'Sense of Place', as told by twitter"
author: Jamie Montgomery
date: '2020-03-31'
slug: santa-barbara-twitter
categories: []
tags: []
---

```{r setup, echo=FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, echo = FALSE, fig.align = "center", out.width = "100%")

library(mapview)
library(tidyverse)
library(sf)
library(leaflet)
library(sp)
library(ggpol) #for the facet_share function
library(RColorBrewer)
library(ggrepel)
library(patchwork)
library(ggmap)
library(ggtext)


tweet_data <- read_csv("~/github/sb_sense_of_place/data/geotagged_sb_tweets_post_apr_2015.csv")
tweet_data_users <- read_csv("~/github/sb_sense_of_place/data/geotag_sb_tweets_user_type.csv")
mapviewOptions(basemaps = c("CartoDB.Positron", "OpenStreetMap"))

register_google(Sys.getenv("GOOGLE_ACCESS_TOKEN"))
```


**The aim of this project was to evaluate whether or not geotagged social media data can be useful in providing insight into a region's "Sense of Place" using Santa Barbara as a case study.** 

How and where people experience and value coastal and ocean areas can reveal places we deem special. Sense of place can be defined as the connection people feel to their geographic surroundings, including both the natural and built environment. Locations with a strong sense of place often have a strong identity felt by both locals and visitors. Sense of place is important for the well-being of both people and the places we value because we are likely to take better care of places that are most important to us. 

Sense of place has been qualitatively studied over time, but more quantitative studies have been lacking due to limited data. Thanks to location-based social media data we now have unprecedented amounts of location and sentiment data, allowing more quantitative exploration of the shared meaning of place.

This project used geotagged twitter data from Santa Barbara, California to see if we can measure Sense of Place with social media data. Specifically I used the data to:  

1. look at how people use natural spaces
2. understand spatial patterns of different user-groups (tourists and locals) 
3. apply a sentiment analysis to learn how positive or negative nature-based tweets are over time

within Santa Barbara.

### Why Santa Barbara?

The easy answer - I live here! Since I know the city and surrounding areas rather well, I could quickly look at spatial patterns and know what is happening in different locations. The total number of tweets coming from Santa Barbara is also more manageable compared to a much larger, urban city. Additionally, this project was done to look specifically at coastal Sense of Place, requiring a location along the coast.

Also, Santa Barbara is known for being a tourist town, and having beautiful natural and built landscapes (ok - I might be a bit biased here) and therefore provides a unique opportunity to look at two distinct "user-groups" (tourists and locals).

# Findings

Not surprisingly, tourists and locals both tweet about nature. Tourists tweet about nature more - nearly 42% of all tourist tweets were nature-based, compared to 30% of local tweets. Spatial patterns reveal that tourists tend to stick to popular tourist sites in town including the wharf, waterfront, zoo, santa barbara bowl and more. Santa Barbara locals are also found at these sites just not as in high a proportion. Overall there is significant overlap in tourist and local patterns within the downtown area, indicating that tourists and locals alike share a fondness for the same areas and things.

This project proves that geotagged twitter data gives you the opportunity to examine how people move within a region, what they care about at certain areas and how user-groups align. Since "Sense of Place" is such a difficult concept to quantify, I think the power of an analysis like this lies in comparison to other regions. If we see that Santa Barbara has a higher than normal rate of visitation to natural areas, or positive sentiment around nature-based tweets compared to other similar regions then maybe we can feel more confident in saying that Santa Barbara has a strong nature-based Sense of Place.

----

# Getting twitter data

When I started working on this I thought that twitter data would be easily accessibly based on the number of different projects I had been seeing that used Twitter data and related R packages. But I quickly learned that this was not the case and Twitter only allows free public access to past 9 days of tweets. This was a problem since we wanted all tweets from January 1, 2015 - December 31, 2019.

Twitter data was obtained freely through an established partnership between UCSB Library and Crimson Hexagon. Before downloading, the data was queried to meet the following conditions:

1. Tweet came from the Santa Barbara area
2. Only original tweets (no retweets)
3. Date was marked between January 1, 2015 and December 31, 2019

Crimson Hexagon only allows 10,000 randomly selected tweets to be exported, manually, at a time in .xls format. Due to this restriction, data was manually downloaded for every 2 days in order to capture all tweets (`r emo::ji('sweat')`). This took a significant amount of point and click time as you can imagine!

Once downloaded, the twitter data did not contain all desired information, including whether or not the tweet was geotagged which was vital to this project. To get this information I stepped outside of my R comfort zone and used the python `twarc` library. This library can  be used to "rehydrate" twitter data using individual tweet ids, and  then store all associated tweet information as .json files. From here I was able to remove all tweets that did not have a geotag, giving a total of **79,981** tweets.

**Some recent good news!** Twitter recently [changed their policy](https://techcrunch.com/2020/03/10/twitter-rewrites-developer-policy-to-better-support-academic-research-and-use-of-good-bots/) for academics looking to use twitter data in their research 🙌🏻! This is great news for anyone looking to use historical twitter data in their research without the funds to purchase access.

## Data overview

The dataset contained `r nrow(filter(tweet_data_users, user_type == "tourist"))` tweets from tourists, `r nrow(filter(tweet_data_users, user_type == "local"))` tweets from locals (`r round(nrow(filter(tweet_data_users, user_type == "tourist"))/nrow(tweet_data_users)*100,0)`% and `r round(nrow(filter(tweet_data_users, user_type == "local"))/nrow(tweet_data_users)*100,0)`%). There are `r nrow(tweet_data_users%>%filter(user_type == "tourist") %>% select(user_type, user_id) %>% distinct())` unique tourists and just `r nrow(tweet_data_users%>%filter(user_type == "local") %>% select(user_type, user_id) %>% distinct())` unique local users.

Here is a sample of the tweet data:

![](/img/tweet_table.png)

### Tweets over time

The total number of geotagged tweets is going down over time and, most noticeably, there is a significant drop in tweets at the end of April, 2015. It seems this is due "a change in Twitter’s ‘post Tweet’ user-interface design results in fewer Tweets being geo-tagged" ( [source](https://developer.twitter.com/en/docs/tweets/data-dictionary/guides/tweet-timeline)). The first 4 months of 2015 have 15,720 tweets, or roughly 19% of all tweets. To reduce a skew in the data and remove geotagged tweets that may have been geotagged without knowledge by the user in those months, *I moved forward with all tweets from May 1, 2015 through the end of 2019*.

```{r tweets_over_time, fig.height = 4}
time_df <- read_csv("~/github/sb_sense_of_place/data/geotagged_sb_tweets.csv") %>%
  group_by(date) %>%
  summarize(count = n())

ggplot(time_df, aes(x = date, y = count)) +
  annotate("rect", fill = "gray80", alpha = 0.4, 
        xmin = as.Date("2015-04-30"), xmax = as.Date("2020-01-01"),
        ymin = -Inf, ymax = 170)  +
  geom_line() +
  geom_smooth() +
  theme_minimal() +
  geom_label(
    data = data.frame(x = c(as.Date("2015-06-15")),
                      y = c(215),
                      label = c("User interface change, results in \nfewer Tweets being geo-tagged")),
    aes(x = x, y = y, label = label), 
    hjust = 0, 
    lineheight = .8, 
    size = 3,
    inherit.aes = FALSE, 
    label.size = 0
  ) +
  geom_curve(
    data = data.frame(x = c(as.Date("2015-06-15")),
                      y = c(214), 
                      xend = c(as.Date("2015-04-30")),
                      yend = c(207)),
    mapping = aes(x = x, y = y, xend = xend, yend = yend),
    colour = "black",
    size = 0.5,
    curvature = 0.05,
    arrow = arrow(length = unit(0.01, "npc"), type = "closed"),
    inherit.aes = FALSE) +
  labs(x = "",
       y = "Count",
       title = "Number of geotagged tweets in Santa Barbara") +
  geom_label(x = as.Date("2019-01-01"), y = 150, 
            label = "Final dataset included tweets \nfrom April 30, 2015 onwards",
            size = 3,   
    label.size = 0)
```

### Tweet map

The majority of tweets align with regional centers of Santa Barbara, Isla Vista (home to UCSB), Santa Ynez Valley and the unincorporated areas of Montecito, Summerland and Carpinteria. As you zoom in on the map, clusters will disaggregate. You can click on blue points to see individual tweet text.

```{r out.width = '100%'}
tweet_sf <- tweet_data %>%
  st_as_sf(coords = c("lon", "lat"), remove = F) %>%
  st_set_crs(4326)

#map
leaflet(tweet_data) %>%
  # Base groups
  addProviderTiles(providers$CartoDB.Positron) %>%
  # Overlay groups %>%
    addCircleMarkers(data = tweet_data, lng = ~lon, lat = ~lat, popup = ~full_text,
                   radius = 3, stroke = FALSE, fillOpacity = 0.5, clusterOptions = markerClusterOptions())
```

----

# Defining tourists & locals

This project aimed to understand if and how preferences differ between tourists and locals for nature-based places within the Santa Barbara area. In order to test this I needed to come up with a way to identify tourists or locals. I ended up using a two step process:

1. If the user has self-identified their location as somewhere in the Santa Barbara area, they are designated a *local*. This includes Carpinteria, Santa Barbara, Montecito, Goleta, Gaviota and UCSB 
2. For the remainder, we use the number of times they have tweeted from Santa Barbara within a year to designate user type. If someone has tweeted across more than 2 months in the same year from Santa Barbara, they are identified as a local. This is consistent with how [Eric Fischer](https://www.citylab.com/transportation/2015/02/where-do-locals-go-in-major-cities-check-out-this-interactive-world-map/385768/) determined tourists in his work. 

This is not fool-proof and there are definitely instances where people visit and tweet from Santa Barbara more than two months a year, especially if they are visiting family or live within a couple hours driving distance, but without more data (and time) to determine where "tourists" truly live, this will have to do.


```{r, echo = FALSE}
tweet_data_users_sf <- tweet_data_users %>%
  st_as_sf(coords = c("lon", "lat"), remove = F) %>%
  st_set_crs(4326)

#santa barbara
sb.map <- get_map("santa barbara, california", zoom = 14, maptype = "toner-lite") 

ggmap(sb.map,  legend="none") +
  coord_equal() +
    labs(x = NULL, y = NULL) +
    theme(axis.text = element_blank()) +
    geom_point(data = tweet_data_users_sf, aes(x = lon, y = lat, color = user_type),
               size = 0.7, alpha = 0.3) + 
    scale_color_manual(values = c("red", "blue")) +
  labs(fill = "User type",
       title = "Santa Barbara tweets from <b style='color:#FF0000'>locals</b> and <b style='color:#0000FF'>tourists</b>") +
  theme(plot.title = element_markdown(lineheight = 1.1, size = 14),
        legend.position = "none")
```


```{r}
#not sure this code is used anywhere else...
hex_grid <- read_sf("~/github/sb_sense_of_place/data/sb_area_hexagons.shp") %>%
  st_set_crs(st_crs(tweet_data_users_sf))

locals   <- tweet_data_users_sf %>% filter(user_type == "local")
tourists <- tweet_data_users_sf %>% filter(user_type == "tourist")

```

----

# What tweets are "nature-based"?

The next step was to understand how these two groups engage with the natural environment within Santa Barbara, and whether or not patterns through time and space could be used to understand what is and is not important to tourists & locals.

Ideally I would've used an established nature "lexicon" (*definition: the vocabulary of a language, an individual speaker or group of speakers, or a subject*) but my search for such a thing turned up empty. So, I created my own dictionary of 67 words that I think would qualify a tweet as being "nature-based". These include recreational words, natural features, animals, and environmental words. I fully recognize this is a dictionary that is biased towards my view of nature-based words and tailored to best capture Santa Barbara centric tweets. I would not recommend this dictionary be used for other non-coastal California areas.

```{r, echo = FALSE}
dictionary <- read_csv("~/github/sb_sense_of_place/data/dictionary.csv")
nature_df <- read_csv("~/github/sb_sense_of_place/data/tweets_nature_categorized.csv")
dictionary$word
```

Let's look at some examples of what tweets qualified as "nature-based". Most of these are in fact nature-based but clearly the third one about burritos and burgers is not. It looks like this tweet was tagged at a local restaurant called "Sandbar" which is why it gets marked as having a nature word ("sand"). This group of tweets also highlights some of the issues with how we assigned locals and tourists. That same user lists their location as "Folsom, CA" which is 6 hours from Santa Barbara. But my method assigned this person as a local which means they must have tweeted from Santa Barbara in at least 3 unique months in a year. One reason for this may be that students at SB City College or UC Santa Barbara are local for most of the year but still use their home location in their twitter profile `r emo::ji('shrug')`.

![](/img/nature_tweet_table.png)

<br>

Again, we see most of the nature-based tweets in Santa Barbara are clustered around high density population centers including State Street, the harbor and the wharf.

```{r}
nature_sf <- nature_df %>%
  st_as_sf(coords = c("lon", "lat"), remove = F) %>%
  st_set_crs(4326)
```

```{r}
#santa barbara
sb.map <- get_map("santa barbara, california", zoom = 14, maptype = "toner-lite") 

ggmap(sb.map,  legend="none") +
  coord_equal() +
    labs(x = NULL, y = NULL) +
    theme(axis.text = element_blank()) +
    geom_point(data = nature_sf %>% filter(nature_word == 1), aes(x = lon, y = lat),
               size = 0.55, alpha = 0.3, color = "darkgreen") + 
  labs(fill = "User type",
       title = "<b style='color:#006400'>Nature-based</b> tweets in Santa Barbara") +
  theme(plot.title = element_markdown(lineheight = 1.1, size = 14),
        legend.position = "none")
```

All groups show increases in proportion of tweets that are nature based over time, even as the number of geotagged tweets declines. 

```{r, fig.height = 4}
nature_prop <- nature_df %>% 
               group_by(date, nature_word) %>%
               summarize(count = n()) %>%
               ungroup() %>%
               group_by(date) %>%
               mutate(total = sum(count),
                      nature_prop = (count/total)*100) %>%
               filter(nature_word == 1) %>%
               mutate(user_type = "all_tweets")

nature_prop_t <- nature_df %>%
               group_by(date, nature_word, user_type) %>%
               summarize(count = n()) %>%
               ungroup() %>%
               group_by(date, user_type) %>%
               mutate(total = sum(count),
                      nature_prop = (count/total)*100) %>%
               filter(nature_word == 1)

combo <- bind_rows(nature_prop, nature_prop_t)


labels <- data.frame(user_type = c("All tweets", "Tourists", "Locals"), 
                     nature_prop = c(31.5, 43, 29)) %>%
                     mutate(date = as.Date("2020-03-29"))


ggplot(combo, aes(x = date, y = nature_prop, color = user_type)) +
  geom_smooth(se = F) +
  theme_minimal() +
  labs(x = "",
       y = "Percentage (%)",
       title = "Proportion of tweets that are nature-based over time") +
  theme(legend.position = "none") +
  geom_text(data = labels, aes(x = date, y = nature_prop, label = user_type)) +
  scale_x_date(expand = expand_scale(mult = c(0, 0.1))) +
  scale_colour_manual(values = c("darkgreen","darkgreen", "purple","purple", "orange", "orange"),
                      labels = c("All tweets", "Tourists", "Locals"))
```

### Are tweets in natural areas more often nature-based?

You would think yes, but this dataset gives us an opportunity to look at what is being tweeted from areas that are designated as "protected" by using the [California Protected Areas Database](https://www.calands.org/). The use of the word "protected" here is a bit loose and includes areas like the Santa Barbara Bowl (an outdoor music venue), and a maritime museum. But, generally, these designated areas are known for their access to nature.

You can see the designated areas within the southern part of Santa Barbara county below:

```{r}
cpad <- read_sf("~/github/sb_sense_of_place/data/cpad_fixed.shp") %>%
  st_set_crs(st_crs(tweet_sf))

cpad_map <- mapview(cpad, zcol = "SITE_NAME", legend = FALSE)
cpad_map@map %>% setView(lng = -119.714, lat = 34.426, zoom = 12)
```

```{r}
nature_sf <- nature_df %>%
    mutate(coords = gsub("\\)|c\\(", "", geo_coordinates)) %>%
    separate(coords, c("lat", "lon"), sep = ", ") %>%
    mutate_at(c("lon", "lat"), as.numeric) %>% 
    st_as_sf(coords = c("lon", "lat")) %>%
    st_set_crs("+init=epsg:4326") %>%
  mutate(tweet_type = ifelse(nature_word == 1, "nature tweet", "non-nature tweet"),
         nature_user = case_when(
            user_type == "local" & nature_word == 0 ~ "local, non nature tweet",
            user_type == "tourist" & nature_word == 0 ~ "tourist, non nature tweet",
            user_type == "tourist" & nature_word == 1 ~ "tourist, nature tweet",
            user_type == "local" & nature_word == 1 ~ "local, nature tweet"
        ))
```

<br>

By overlaying the twitter dataset with this map I can look at the number of tweets per area, types of tweets (nature or not) and who is tweeting/visiting these areas. This chart shows the top 20 most popular tweeted-from sites. The green highlighted portion represents nature-based tweets. The number indicates what percentage of all tweets are nature-based at each site. Names in **bold** indicate over 50% of tweets are nature-based.

One surprising thing is the most tweeted from place is Manning Park in Montectio. Even though I've lived in Santa Barbara for 9 years, I had never heard of this small park! I dug into this and it looks like the default geotag for "Montecito, California" uses a coordinate that just happens to fall within the park boundaries, which explains why we see a smaller proportion of nature-based tweets from this "nature-based area".

```{r, echo = FALSE}
nature_tweets <- nature_sf %>%
  filter(nature_word == 1)
non_nature_tweets <- nature_sf %>% 
  filter(nature_word == 0)

cpad_all_count <- cpad %>%
  mutate(total_tweets = lengths(st_intersects(cpad, nature_sf)),
         nature_count = lengths(st_intersects(cpad, nature_tweets)),
         non_nature_count = lengths(st_intersects(cpad, non_nature_tweets))) %>%
  rowwise() %>%
  mutate(ratio = nature_count/non_nature_count,
         prop  = nature_count/total_tweets) %>%
  filter(!is.na(ratio)) %>%
  mutate(ratio = ifelse(is.infinite(ratio), nature_count, ratio)) %>% 
  st_set_geometry("geometry")
```

```{r}
top_20 <- cpad_all_count %>%
  st_set_geometry(NULL) %>%
  arrange(-nature_count) %>%
  slice(1:20) %>%
  pivot_longer(cols = c(nature_count, non_nature_count), names_to = "tweet_type", values_to = "count")

top_20_prop <- top_20 %>% 
  select(SITE_NAME, prop, count) %>%
  group_by(SITE_NAME, prop) %>%
  summarise(count = sum(count)) %>%
  ungroup() %>%
  distinct() %>%
  mutate(prop = paste0(round(100*prop,0),"% "))

ggplot(top_20, aes(x = reorder(SITE_NAME, count), fill = tweet_type, y = count)) +
  geom_bar(stat = "identity", position = "stack") +
  theme_minimal() +
  coord_flip() +
  labs(x = "",
       y = "Number of tweets",
       fill = "",
       title = "Top 20 most tweeted from CPAD areas in Santa Barbara") +
  scale_fill_manual(values = c("darkgreen", "gray"), labels = c("Nature-based", "Other")) +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 3.3),
        axis.text.y = element_text(face = rev(c('plain', 'bold', 'plain', 'plain', 'bold', 'bold', 'bold', 'plain', 'plain', 'bold','bold','bold','bold','bold','bold','bold','bold','plain','bold','bold'))))  +
    geom_text(aes(SITE_NAME, y = count, label = prop, fill = NULL), 
              data = top_20_prop, hjust = -0.05, size = 3) +
  ylim(0, 1510)
```

What I take away from this is that most of the designated CPAD areas have a majority of nature-based tweets, indicating that most visitors to these areas are there to engage with nature.

# Do tourists and locals visit the same or different natural sites?

Going a bit further, I also looked at number of unique visitors to these CPAD sites. By calculating the proportion of unique tourists and locals that visit these sites, we start to look at who goes where. *This is not limiting tweets to only those that are nature-based.*

At the lower end we see more locals than tourists visiting these sites. These tend to be less popular areas. On the upper end, we see sites that are more frequented overall, and more frequented by tourists. These include well-known areas like the Santa Barbara Harbor and Stearn's Wharf. Those on the lower end that locals frequent more are either lesser-known (Shoreline Park, Alameda Park are both neighborhood parks), or further from main tourist areas (e.g. Goleta Beach)

```{r}
tweets_in_cpad <- read_sf("~/github/sb_sense_of_place/data/tweets_in_cpad_areas.shp")

twt_df <- tweets_in_cpad %>%
  select(user_id, usr_typ, SITE_NA) %>%
  st_set_geometry(NULL) %>%
  distinct() %>%
  group_by(SITE_NA, usr_typ) %>%
  summarize(count = n()) %>%
  ungroup() %>%
  group_by(usr_typ) %>%
  mutate(total_users = sum(count)) %>%
  ungroup() %>%
  mutate(prop = count/total_users) %>%
  select(-total_users, -count) %>%
  pivot_wider(names_from = usr_typ, values_from = prop) %>%
  mutate(local = ifelse(is.na(local), 0, local),
         tourist = ifelse(is.na(tourist), 0, tourist),
    label = ifelse(
      SITE_NA %in% c("Arroyo Burro Beach County Park", "Santa Barbara Harbor", "Stearns Wharf", "Los Padres National Forest", "Carpinteria State Beach", "Santa Barbara Bowl", "Santa Barbara Maritime Museum", "Manning Park", "Santa Barbara Zoological Gardens", "Chase Palm Park"), as.character(SITE_NA), ""),
    fill = ifelse(tourist > local, "fill", "empty"))
  
p1 <- ggplot(twt_df, aes(x = local, y = tourist)) +
  geom_point(aes(color = fill), size = 2) +
  scale_color_manual(values = c("red", "blue")) +
  geom_abline(color = "gray") +
  theme_classic() +
  theme(legend.position = "none") +
  geom_text_repel(aes(label = label), size = 2.2, min.segment.length = 0.5, point.padding = 0.3, segment.alpha =0.4) +
  geom_curve(data = data.frame(x = 0.03,
                      y = 0.005, 
                      xend = 0.1,
                      yend = 0.005),
    mapping = aes(x = x, y = y, xend = xend, yend = yend),
    colour = "black",
    size = 0.5,
    curvature = 0.05,
    arrow = arrow(length = unit(0.01, "npc"), type = "closed"),
    inherit.aes = FALSE) +
  labs(x = "Locals",
       y = "Tourists", 
       title = "Proportion of <b style='color:#FF0000'>locals</b> & <b style='color:#0000FF'>tourists</b> visiting",
       subtitle = "CPAD areas") +
  ggplot2::annotate("rect", fill = "gray80", alpha = 0.5, 
        xmin = -Inf, xmax = 0.03,
        ymin = -Inf, ymax = 0.03) +
  theme(plot.title = element_markdown(lineheight = 1.1, size = 11),
        legend.position = "none") +
   geom_label(
    data = data.frame(x = 0.015,
                      y = 0.12,
                      label = c("10.6% of all tourists \nvisit Stearn's Wharf but \njust 5.2% of locals visit")),
    aes(x = x, y = y, label = label), 
    hjust = 0, 
    lineheight = .8, 
    size = 2.5,
    inherit.aes = FALSE, 
    label.size = 0,
    color = "gray30"
  ) +
  geom_curve(
    data = data.frame(x = 0.031,
                      y = 0.113, 
                      xend = 0.051,
                      yend = 0.107),
    mapping = aes(x = x, y = y, xend = xend, yend = yend),
    colour = "black",
    size = 0.5,
    curvature = 0.05,
    arrow = arrow(length = unit(0.01, "npc"), type = "closed"),
    inherit.aes = FALSE)

```

```{r, fig.height = 4}
lower_end <- twt_df %>% 
  filter(local < 0.04 & tourist < 0.04) %>%
  mutate(local = ifelse(is.na(local), 0, local),
         tourist = ifelse(is.na(tourist), 0, tourist),
    label = ifelse(
      SITE_NA %in% c("Cachuma Lake Recreation Area", "Leadbetter Beach", "Goleta Beach County Park", "Shoreline Park", "Coal Oil Point Reserve", "Alameda Park", "Douglas Family Reserve", "El Presidio de Santa Barbara State Historic Park"), as.character(SITE_NA), ""),
    fill = ifelse(local > tourist, "fill", "empty"))

p2 <- ggplot(lower_end, aes(x = local, y = tourist)) +
  geom_point(aes(color = fill), size = 2) +
  scale_color_manual(values = c("blue", "red")) + 
  geom_abline(color = "gray") +
  theme_classic() +
  theme(legend.position = "none") +
  geom_text_repel(aes(label = label), size = 2.2, min.segment.length = 0.5, point.padding = 0.3, segment.alpha =0.4) +
  labs(x = "Locals", y = "", title = "")

p1+p2 + plot_layout(ncol=2)
```


## Sentiment Analysis

Lastly, I wanted to do a sentiment analysis to see if the general feeling of nature-based tweets was positive/negative and how they are changing over time. Using the `tidytext` package, I applied a general sentiment lexicon called *bing* to every single tweet in the dataset. The *bing* lexicon "categorizes words in a binary fashion into positive and negative categories". From here we can look at averages over time. While there are expected fluctuations in tweet sentiments day by day, I applied a smoothed mean for a better look at changes over time. 

The top graphs show the total number of geotagged tweets, which has gone down over time across all groups. The bottom graphs shows average daily sentiment scores over time. Above 0 is positive, below 0 is negative. 

**We see that on average tweets from Santa Barbara are positive and continue to grow in "positivity" over time**

```{r}
#sentiment score over time for all tweets
bing_scores <- read_csv("~/github/sb_sense_of_place/data/all_tweets_bing_score.csv") %>%
  mutate(type = "all_tweets")

sb <- bing_scores %>%
  select(date, avg_score = avg_daily_score) %>%
  distinct() %>%
  mutate(type = "All Tweets")

sb_nat <- bing_scores %>%
  group_by(date, nature_word) %>%
  summarize(avg_score = mean(score)) %>%
  mutate(type = ifelse(nature_word == 1, "All SB nature tweets", "All SB non-nature tweets")) %>%
  select(-nature_word)

allsb <- bind_rows(sb, sb_nat)


labels <- data.frame(type = c("Nature-based", "Non-nature based", "All"), 
                     avg_score = c(0.7, 0.28, 0.6)) %>%
                     mutate(date = 
                              c(as.Date("2019-08-01"), 
                                as.Date("2018-07-01"), 
                                as.Date("2018-10-20")))


p1 <- ggplot(time_df %>% filter(date > "2015-04-28"), aes(x = date, y = count)) +
  geom_line() +
  geom_smooth() +
  theme_classic() +
  labs(x = "",
       y = "Count",
       title = "All tweets")

p2 <- ggplot(data = allsb, aes(x = date, y = avg_score, color = type)) +
  geom_smooth(se = F) +
  theme_classic() +
  theme(legend.position = "none") +
  labs(y = "Score", x= "", title = "Average sentiment") +
  geom_text(data = labels, aes(x = date, y = avg_score, label = type), size = 2.5) +
  scale_x_date(expand = expand_scale(mult = c(0, 0.1))) +
  scale_colour_manual(values = c("black", "darkgreen", "gray50", "black", "darkgreen", "gray50"),
                      labels = c("Nature-based", "Non nature-based", "All" ))
```

```{r}
#sentiment scores for tourists - nature and nonnature
t_n <- bing_scores %>%
  filter(user_type == "tourist" & nature_word == 1) %>%
  group_by(date) %>%
  summarize(avg_score = mean(score)) %>%
  mutate(type = "Tourist nature")
t_nn <- bing_scores  %>%
  filter(user_type == "tourist" & nature_word == 0) %>%
  group_by(date) %>%
  summarize(avg_score = mean(score)) %>%
  mutate(type = "Tourist non-nature")

combo <- bind_rows(t_n, t_nn)

tourist_tweet_count <- tweet_data_users %>% 
                        filter(date > "2015-04-28",
                               user_type == "tourist") %>%
                        group_by(date) %>%
                        summarize(count = n())

p3 <- ggplot(tourist_tweet_count, aes(x = date, y = count)) +
  geom_line() +
  geom_smooth() +
  theme_classic() +
  labs(x = "",
       y = "",
       title = "Tourists")


p4 <- ggplot(data = combo, aes(x = date, y = avg_score, color = type)) +
  geom_smooth(se = F) +
  theme_classic() +
  theme(legend.position = "none") +
  labs(y = "", x= "", title = "")  +
  scale_x_date(expand = expand_scale(mult = c(0, 0.1))) +
  scale_colour_manual(values = c("darkgreen","gray30", "darkgreen", "gray50"),
                      labels = c("", ""))

```

```{r}

l_n <- bing_scores %>%
  filter(user_type == "local" & nature_word == 1) %>%
  group_by(date) %>%
  summarize(avg_score = mean(score)) %>%
  mutate(type = "Local nature")
l_nn <- bing_scores  %>%
  filter(user_type == "local" & nature_word == 0) %>%
  group_by(date) %>%
  summarize(avg_score = mean(score)) %>%
  mutate(type = "Local non-nature")

combo <- bind_rows(l_n, l_nn)


local_tweet_count <- tweet_data_users %>% 
                        filter(date > "2015-04-28",
                               user_type == "local") %>%
                        group_by(date) %>%
                        summarize(count = n())

p5 <- ggplot(local_tweet_count, aes(x = date, y = count)) +
  geom_line() +
  geom_smooth(se = F) +
  theme_classic() +
  labs(x = "",
       y = "",
       title = "Locals")

p6 <- ggplot(data = combo, aes(x = date, y = avg_score, color = type)) +
  geom_smooth(se = F) +
  theme_classic() +
  theme(legend.position = "none") +
  labs(y = "", x= "", title = "") +
  scale_x_date(expand = expand_scale(mult = c(0, 0.1))) +
  scale_colour_manual(values = c("darkgreen","gray30", "darkgreen", "gray50"),
                      labels = c("", ""))


p1  + p3 + p5+ p2 + p4 + p6 + plot_layout(ncol=3)
```

### What are people tweeting about?

To see what people are tweeting about I applied a **Term Frequency-Inverse Term Frequency (TF-IDF)** analysis, which identifies words within tweets that are not only most common (e.g. "the", "to", "santa barbara"), but most "important". TF-IDF is measure of how important a word is to a document in a corpus of documents, or in this case how important a word is to all nature-based tweets.

Clearly **beach** is the winner here!

![](/img/sb_nature_tweets_top_words.png)

I applied the same analysis to each CPAD areas. Admittedly, this will be most interesting for people familiar to Santa Barbara. Douglas Family Preserve is a known off-leash dog park, which is why we see "dog" and "leash" at the 2 and 3 spots. Ellwood Mesa has a small Monarch butterfly preserve, hence the presence of "butterfly", and East Beach is the place to go to play beach volleyball.

![](/img/cpad_tweets_top_words.png)

And finally, I couldn't end the project without doing a wordcloud for all of Santa Barbara!

![](/img/wordcloud_top_100_all_sb.png)

----

## Closing thoughts

### Geotagged social media data in conservation

Geotagged social media data has been used in recent years to study people's interaction with the natural environment in various ways, many of which are focused on tourism:  

- Quantifying nature-based tourism ( [Wood et al. 2013](https://www.nature.com/articles/srep02976/), [Kim et al. 2019](https://www.sciencedirect.com/science/article/pii/S0261517718303091)) 
- Mapping tourist footprints ( [Runge & Daigle 2020](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0227189)), flows ([Chua et al. 2016](https://www.sciencedirect.com/science/article/abs/pii/S0261517716301005)), and hot spots ([Garcia-Palomares et al. 2015](https://www.sciencedirect.com/science/article/abs/pii/S0143622815001952)) 
- Understand tourist preferences in nature based places such as Kruger National Park ([Hausmann et al. 2017](https://conbio.onlinelibrary.wiley.com/doi/full/10.1111/conl.12343), [Levin et al. 2017](https://www.landscapevalues.org/publications/crowd_JAPG_final.pdf), [Tenkanen  et al. 2017](https://www.nature.com/articles/s41598-017-18007-4)) 
- Monitor and measure environmental conditions of places (e.g. Great Barrier Reef, [Becken et al. 2017](https://www.ncbi.nlm.nih.gov/pubmed/28779604)) 

This project differed in that I wanted to map the spatial patterns of tourists and locals, and understand how these two user groups engage with and perceive the natural environment of Santa Barbara. 

### Future research opportunities

Applying the same or similar method to other regions of different geographic and population sizes could reveal more interesting information and provide context for the patterns and trends we see in Santa Barbara. We might expect the tourist/local alignment to differentiate when looking at highly urban areas (LA, San Francisco), show more alignment in other suburban areas (e.g. Santa Cruz), and maybe not exist in rural locations.

By making comparisons to more rural and urban regions, we could start asking if Santa Barbara is unique in that:  

* tourists and locals have similar spatial patterns  
* 24% of all geo-tagged tweets are nature-based (seems high!) 
* the proportion of nature-based tweets is increasing as geotagged tweets decrease overall, and positive sentiment is increasing over time  

If we look at proportion of tweets that are nature-based across these rural-suburban-urban scales, we may reveal where sentiments or Sense of Place around the natural environment are higher or lower. For example, we would expect a lower proportion of nature-based tweets in New York compared to Santa Barbara. We could also compare the city to state level. Across all geotgagged tweets in California, what is the proportion of nature-based tweets?

### Areas for refinement

If this method is replicated going forward, there are a few areas where refinement and better data could be improved.

**Identifying tourists and locals**  
If I had access to a larger twitter dataset, I could identify where tourists are "from" (or where they tweet more consistently) to confirm their tourist status, instead of relying on the number of months a user tweets within an area.

**Nature-based dictionary**   
The dictionary compiled for this project was based solely on my own perspective of nature-based words. It also leaned heavily on what I would expect people to tweet about in Santa Barbara (e.g. "lobster", "islands", "wharf"). Ideally a dictionary used to identify nature-based tweets would be developed using more robust methods across a more geographically representative area. 

**Spatial data for natural areas**  
The CPAD dataset is good but not perfect. Some place names needed to be edited and some polygons needed to be fixed. This would not have been possible without extensive local knowledge of Santa Barbara. To scale this analysis to larger areas, you would want to ensure the underlying "natural area" dataset is appropriate.

**Bias in data**  
There is inherent bias in using social media data to draw broader conclusions about a community. Not everyone has access to social media or uses social media in a similar manner. There are differences across all demographics (genders, ages, ethinicities, economic status) and these were not taken into consideration during this project but should be considered if this is to be expanded upon. There are also differences in who decides to make their account public and explicilty chooses to geotag their tweet (Sloan & Morgan 2015).


<br>
All code is available at this [github repo](https://github.com/ohi-science/sb_sense_of_place). Twitter data is kept offline and secure at the National Center for Ecological Analysis & Synthesis.